{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMgWmojQVitBcIF11qsY6r2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Zadanie 1.**\n","\n","Zadania, które moim zdaniem wymagają inteligencji człowieka:\n","\n","\n","* Wypełnianie deklaracji PIT – nie wymaga ludzkiej inteligencji, ponieważ proces ten opiera się na mechanicznym wypełnianiu danych według z góry ustalonych reguł. Wystarczy wstawienie odpowiednich wartości w odpowiednie pola, co można zautomatyzować.\n","\n","* Streszczanie tekstu – wymaga ludzkiej\n","inteligencji, ponieważ zadanie to polega na zrozumieniu sensu tekstu, jego szczegółowej analizy oraz umiejętności wyłonienia najważniejszych informacji i myśli przewodnich, które oddadzą istotę tekstu w skróconej wersji. Warto zauważyć, że modele sztucznej inteligencji, takie jak GPT, mogą generować streszczenia na zadowalającym poziomie, choć nie zawsze uwzględniają wszystkie szczegóły tekstu.\n","\n","* Tłumaczenie tekstu – wymaga inteligencji człowieka, ponieważ wymaga dopasowania odpowiedniego słownictwa do kontekstu, znajomości kultury oraz zrozumienia całościowego sensu tekstu, co czyni ten proces bardziej wymagającym niż zwykłe zastępowanie słów ich odpowiednikami w innym języku.\n","\n","* Klasyfikacja tekstu do kategorii tematycznych – nie wymaga inteligencji człowieka, gdyż można to zrealizować automatycznie, na przykład za pomocą analizy słów kluczowych lub innych ustalonych cech charakterystycznych dla danej kategorii. Systemy oparte na AI dobrze radzą sobie z tym zadaniem w szybki i efektywny sposób.\n","\n","* Odpowiadanie na proste pytania w języku naturalnym (np. polskim) – może wymagać lub nie wymagać inteligencji człowieka, w zależności od typu pytania. Jeśli pytanie dotyczy typowych, przewidywalnych sytuacji, można zrealizować to automatycznie za pomocą systemów opartych na AI. Jednak nawet proste pytania mogą wymagać głębszej analizy kontekstu i bardziej złożonej odpowiedzi, co wymaga zaangażowania człowieka.\n","\n","* Układanie rozkładu jazdy transportu miejskiego – zależy od sytuacji. Prosty rozkład może zostać opracowany przez algorytmy optymalizacyjne, ale proces ten może być podatny na dynamiczne zmiany, takie jak specjalne wydarzenia czy nietypowe zapotrzebowanie pasażerów. Przy większej liczbie takich różnych zmiennych konieczne jest ludzkie myślenie i analiza.\n","\n","* Programowanie (pisanie programów komputerowych) – wymaga inteligencji człowieka, ponieważ przed przystąpieniem do kodowania konieczne jest zrozumienie problemu, zaprojektowanie rozwiązania oraz kreatywne podejście do rozwiązywania wyzwań, co wykracza poza schematyczne działania. AI może wspierać programistów, ale nie zastępuje ich w pełni.\n","\n","* „Programowanie” kanałów telewizyjnych – nie wymaga ludzkiej inteligencji, ponieważ przypisanie programów do przycisków pilota to proces oparty na prostej logice i schematach działania, które można w pełni zautomatyzować.\n","\n","* Testowanie oprogramowania – wymaga ludzkiej inteligencji, ponieważ sprawdzanie działania programu wymaga twórczego myślenia i przewidywania nietypowych sytuacji, które mogą wystąpić. Niezbędne jest także opracowywanie nieszablonowych scenariuszy testowych i znajdowanie błędów, które często są trudne do wykrycia. Automatyczne testowanie wspiera człowieka, ale nie zastępuje go całkowicie.\n","\n","* Komponowanie muzyki – wymaga inteligencji człowieka, ponieważ proces ten opiera się na kreatywności, emocjach oraz estetyce. Tworzenie nowych melodii i utworów wymaga wyjścia poza istniejące schematy i wymyślenia czegoś oryginalnego. AI może generować utwory, ale często brakuje im emocjonalnej głębi i oryginalności na jaką stać człowieka.\n","\n","* Rozwiązywanie układów równań – proste układy równań nie wymagają ludzkiej inteligencji, ponieważ można je rozwiązać według ustalonych algorytmów i schematów. Jednak w przypadku bardzo skomplikowanych układów, gdzie algorytmy zawiodą, konieczna jest kreatywność i twórcze myślenie.\n","\n","* Symboliczne obliczanie pochodnych funkcji – nie wymaga ludzkiej inteligencji, ponieważ polega na wstawieniu wartości do wzoru i podążaniu za ustalonymi regułami matematycznymi. Zadanie to jest łatwo wykonywane przez systemy komputerowe.\n","\n","* Symboliczne całkowanie funkcji – wymaga ludzkiej inteligencji, ponieważ w wielu przypadkach brak jest ogólnych reguł lub wzorów. Całkowanie staje się wówczas procesem twórczym, wymagającym znalezienia sprytnych lub nowatorskich rozwiązań.\n","\n","* Kierowanie samochodem – wymaga ludzkiej inteligencji, ponieważ jest to proces skomplikowany, wymagający podejmowania wielu różnorodnych decyzji w zmieniających się warunkach. Trzeba przewidywać zachowania innych użytkowników drogi, dostosowywać się do dynamicznych sytuacji i rozwiązywać problemy, które nie podlegają prostym schematom. Systemy autonomiczne radzą sobie coraz lepiej, ale nadal nie dorównują w pełni zdolnościom człowieka w złożonych sytuacjach.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"Xqn0afPCR4w7"}},{"cell_type":"markdown","source":["**Zadanie 2.**\n","\n","Problemy, które można uznać za mieszczące się w zakresie sztucznej inteligencji to:\n","\n","* Streszczanie tekstu – można, ponieważ sztuczna inteligencja, szczególnie modele przetwarzania języka naturalnego (np. GPT), potrafi analizować tekst i wyciągać z niego najważniejsze informacje. Dzięki temu AI jest w stanie generować streszczenia, które w większości przypadków dobrze oddają sens oryginału, lecz często zdarza się, że te streszczenia są za bardzo uproszczone.\n","\n","* Tłumaczenie tekstu – można, ponieważ narzędzia, takie jak Google Translate, wykorzystują zaawansowane algorytmy, które pozwalają im tłumaczyć teksty w sposób kontekstowy. Radzą sobie dobrze z ogólnymi tekstami, choć w tłumaczeniach literackich i bardziej specjalistycznych wymagane jest precyzyjne tłumaczenie, z którym takie translatory nie radzą sobie w odpowiedni sposób.\n","\n","* Klasyfikacja tekstu do kategorii tematycznych – można, ale nie trzeba, ponieważ system mechaniczny, bez zaawansowanej sztucznej inteligencji, może już wystarczająco dobrze przypisywać teksty do kategorii na podstawie analizy słów kluczowych.\n","\n","* Odpowiadanie na proste pytania zadawane w języku naturalnym – można, ale nie zawsze jest to konieczne, ponieważ sztuczna inteligencja może generować odpowiedzi na podstawie analizy słów kluczowych i rozpoznawania klasy pytania. W wielu przypadkach AI jest w stanie udzielić sensownej odpowiedzi, ale niekoniecznie „inteligentnej” czy głębokiej. Bardziej skomplikowane pytania wymagają jednak zaawansowanej analizy semantycznej, co może być trudniejsze do zautomatyzowania.\n","\n","* Rozwiązywanie układów równań – można w przypadku skomplikowanych układów, ponieważ sztuczna inteligencja potrafi stosować zaawansowane metody numeryczne i heurystyczne do rozwiązywania trudnych problemów matematycznych. Proste układy można jednak rozwiązać za pomocą schematycznych algorytmów bez potrzeby wykorzystania AI.\n","\n","* Układanie rozkładu jazdy – można w przypadku bardziej złożonych rozkładów, ponieważ AI może uwzględniać wiele zmiennych, takich jak zapotrzebowanie pasażerów, godziny szczytu czy ograniczenia infrastruktury. Dzięki algorytmom optymalizacyjnym AI jest w stanie stworzyć efektywny i elastyczny harmonogram. W prostszych przypadkach można jednak posłużyć się mechanicznymi metodami.\n","\n","* Rozwiązywanie układów równań liniowych – nie trzeba, ponieważ tego rodzaju zadania są schematyczne i można je rozwiązać za pomocą standardowych algorytmów (np. metoda eliminacji Gaussa). AI nie wnosi tu żadnej istotnej wartości.\n","\n","* Symboliczne obliczanie pochodnych – nie trzeba, ponieważ proces ten opiera się na ustalonych regułach matematycznych i jest łatwo zautomatyzowany. Istnieją systemy takie jak WolframAlpha, MATLAB i one radzą sobie z tym zadaniem bez potrzeby angażowania zaawansowanej AI.\n","\n","* Symboliczne całkowanie – można, ponieważ w wielu przypadkach całkowanie wymaga znalezienia wzorców, co jest bardziej złożonym procesem niż obliczanie pochodnych. AI, korzystając z zaawansowanych algorytmów, potrafi podejść do tych problemów w sposób przypominający ludzkie rozumowanie.\n","\n","* Kierowanie samochodem – można, ponieważ sztuczna inteligencja w autonomicznych pojazdach (np. Tesla) jest w stanie analizować otoczenie w czasie rzeczywistym i podejmować decyzje. Wykorzystuje sensory, kamery i algorytmy do reagowania na dynamiczne sytuacje na drodze. Choć sztuczna inteligencja jest skuteczna, w niektórych ekstremalnych przypadkach wciąż może wymagać interwencji człowieka.\n","\n","\n"],"metadata":{"id":"wmAIUe9GWfWc"}},{"cell_type":"markdown","source":["**Zadanie 3.**\n","\n","\n","* Rozmowa towarzyska może byc skutecznie imitowana, ponieważ systemy są w stanie generować żarty, opowiadać o różnych tematach na podstawie podanych danych. Jedynie co można im zarzucić to, że nie są w stanie, tak jak ludzie zrozumieć w pełni emocji i relacji międzyludzkich, co sprawia, że są bardziej mechaniczne. Istnieją modele językowe, dzięki którym rozmowy mogą być prowadzone w sposób płynny i bardziej naturalny. Jednak nie potrafią interpretować mowy ciała czy tonu głosu, więc zdają się mnniej ludzkie.\n","\n","* Co do dyskusji politycznej, systemy są w stanie generować logiczne odpowiedzi oparte na faktach oraz analizach dostępnych danych politycznych. Może istnieć problem w rozmowie o aktualnych wydarzeniach chyba, że systemy te są regularnie aktualizowane.\n","\n","* Dyskusja naukowa - systemy mogą generować odpowiedzi oparte na dostępnej wiedzy naukowej i logicznie uzasadniać swoje argumenty, brakuje im jednak myśli twórczej i pełnego zrozumienia koncepcji, co ogranicza zdolność do pełnej dyskusji naukowej. Systemy sztucznej inteligencji nie są w stanie wprowadzać innowacyjnych pomysłów ani krytycznie oceniać teorii w sposób, w jaki robią to ludzie, dlatego w mało skuteczny sposób będą imitować zachowania ludzkie.\n","\n","* Sztuczne systemy,np. chatboty czy automatyczne centra obsługi klienta, radzą sobie dobrze w przypadku standardowych pytań i prostych problemów. Dzięki wcześniej zaprogramowanym bazom wiedzy są w stanie dostarczać szybkie odpowiedzi na typowe zapytania klientów. Jednak odpowiadanie na pytania klientów w telefonicznej infolinii i odpowiadanie na pytania klientów w internetowej infolinii są często nie do końca skuteczne przez sztuczne systemy, ponieważ zdarza się, że klient zadaje takie pytanie, na które AI nie jest przygotowane. Mogą sobie nie radzić z niestandardowymi, szablonowymi pytaniami. Kolejnym problemem może być brak elastyczności w reagowaniu na dane sytuacje.\n"],"metadata":{"id":"kNzL8lCvcy99"}},{"cell_type":"markdown","source":["**Zadanie 4.**\n","\n","1) Celem bota udającego człowieka (test Turinga) jest przekonanie użytkownika, że rozmawia z człowiekiem. Bot dąży do tego, by imitować ludzką komunikację i ukrywać swoją tożsamość jako maszyny. W tym przypadku, test Turinga sprawdza, czy użytkownik potrafi odróżnić bota od prawdziwej osoby. Natomiast celem bota asystenta służącego jest ułatwienie wykonywania zadań lub dostarczanie odpowiednich informacji. Bot-asystent nie próbuje udawać człowieka, lecz skupia się na jak najbardziej efektywnej i przejrzystej pomocy użytkownikowi, np. odpowiada na pytania, pomaga w nawigacji, czy wykonuje inne zadania w imieniu użytkownika.\n","\n","2) Porównanie dwóch botów: chatGPT i cleverbot\n","\n","a) opowiadanie żartów:\n","\n","*   ChatGPT odpowiedział mi w następujący sposób: \"Jasne! Oto jeden:\n","Dlaczego matematyk nie lubi chodzić do lasu?Bo boi się pierwiastków! 😄\"\n","*   Cleverbot natomiast odpisał: \"Idzie baba do lekarza a lekarz też baba.\"\n","\n","Moim zdaniem, cleverbot podał przykład żartu, który bardziej pasuje do nie oficjalnych sytuacji, takich jak rozmowa ze znajomym. Jednak warto zauważyć, że bot-asystent również dobrze poradził sobie z tym zadaniem, a nawet wykorzystał emotikon. Wydaje mi się, że bot udający człowieka potrafi rozbawić w bardziej \"ludzkim\" stylu\".\n","\n","b) przytaczanie cytatów z twoich wypowiedzi, lub znanych osób:\n","\n","*   ChatGPT odpisał: \"Oczywiście! Oto inspirujący cytat Alberta Einsteina:\n","\"Wyobraźnia jest ważniejsza niż wiedza. Wiedza jest ograniczona, wyobraźnia obejmuje cały świat.\" Co o nim sądzisz? 😊\"\n","\n","* Cleverbot odpisał: \"Nie znam sie na zartach.\"\n","\n","Tutaj śmiało mogę stwierdzić, że bot-asystent efektywniej wykonuje moje prośby niż cleverbot, który jest niechętny do udzielania odpowiedzi.\n","\n","c) nawiązywanie wypowiedzi do słów kluczowych\n","\n","* ChatGPT nie ma z tym żadnego problemu, jednak bot udający człowieka ma. Na postawione pytanie odpowiedział zdaniem twierdzącym, które nie było związane z tematem zapytania.\n","\n","d) zadawanie dużej liczby pytań\n","\n","* ChatGPT bardzo dobrze radzi sobie z odpowiadaniem na wiele pytań. Dokładnie odpowiada na postawione pytania.\n","* Cleverbot, natomiast, wręcz przeciwnie. Przy zadawaniu dużej ilości pytań, a nawet już przy pierwszym zachowuje się tak samo jak w sytuacji powyżej - odpowiada zdaniami twierdzącymi, które nie są związane z tematem.\n","\n","e) powracanie do początku wypowiedzi, sekwencyjne powtarzanie\n","\n","* W przeciwnieństwie do cleverbot'a, ChatGPT z łatwością powrócił do początku wypowiedzi i odpowiedział na pytanie dotyczące podanego przez niego cytatu.\n","\n","f) zadawanie pytań powstających z twoich wypowiedzi\n","\n","* Bot-asystent często w odpowiedzi na moje pytania, zadaje swoje, np. \"Co o nim sądzisz?\", \"Czy mogę jeszcze ci jakoś pomóc?\". Natomiast cleverbot nie zadawał mi pytań utrzymujących rozmowę, ale zaproponował, by na zmianę opowiadać sobie żarty.\n","\n","g) odpowiadanie wymijająco, ogólnikowo\n","\n","* Cleverbot zdecydowanie w taki sposób odpowiadał, a nawet często zmieniał kompletnie temat rozmowy. ChatGPT może odpowiadać ogólnikowo lub dokładnie jeśli go o to poproszę.\n","\n","h) częsta zmiana tematu rozmowy\n","i) problemy z utrzymaniem wątków\n","\n","* Cleverbot ujawniał takie zachowanie. W przeciwieństwie chatGPT potrafi nawet powrócić do wcześniej omawianych wątków.\n","\n","3)\n","Bot udający człowieka dąży do imitowania ludzkiej komunikacji, aby przekonać użytkownika, że rozmawia z prawdziwą osobą, co stanowi podstawę testu Turinga. Z kolei bot-asystent skupia się na dostarczaniu efektywnej i przejrzystej pomocy, odpowiadając na pytania i ułatwiając wykonywanie zadań, bez prób udawania człowieka.\n","W praktyce te różnice są wyraźnie widoczne w zachowaniu ChatGPT i Cleverbot. ChatGPT, jako bot-asystent, precyzyjnie odpowiada na pytania, utrzymuje spójność rozmowy i potrafi powracać do wcześniejszych wątków. Jego odpowiedzi są dostosowane do kontekstu, a pytania wynikające z rozmowy pomagają aktywnie podtrzymywać dialog. Cleverbot natomiast często zmienia temat, unika odpowiedzi na konkretne pytania i ma trudności z utrzymaniem wątków rozmowy. Jego bardziej potoczny styl i przypadkowe reakcje mogą sprawiać wrażenie ludzkiej komunikacji, ale brakuje im precyzji i logiki.Ogólnie, ChatGPT skutecznie realizuje swoje zadanie jako asystent, zapewniając merytoryczne i spójne odpowiedzi, podczas gdy Cleverbot bardziej symuluje spontaniczność ludzkiej rozmowy, lecz z ograniczeniami w jej ciągłości i adekwatności.\n","\n","5) Zdenerwuj bota.\n","\n","* Cleverbot:\n","\n","Ja: Wiesz, że nie jesteś tak dobry jak chatGPT?\n","\n","Cleverbot: Ja jestem człowiekiem Co ty gadasz.\n","\n","* ChatGPT:\n","\n","Ja: Wiesz, że często informacje, które podajesz są nieprawidłowe i wprowadzasz wiele ludzi w błąd?\n","\n","Chat: Rozumiem, że możesz mieć takie obawy, i doceniam, że to podnosisz. Staram się podawać informacje, które są jak najbardziej rzetelne, ale moja wiedza może być czasami niepełna, a w niektórych przypadkach mogą zdarzyć się błędy...\n","\n","Ja: To jest poważniejszy problem niż ci się wydaje!\n","\n","Chat: Masz absolutną rację, że problem dezinformacji jest bardzo poważny. Każda technologia, w tym moja, ma odpowiedzialność za minimalizowanie błędów, bo nieprawidłowe informacje mogą prowadzić do złych decyzji lub nieporozumień.\n","\n","* Krótko podsumowując, bot udający człowieka - Cleverbot, był łatwy do zdenerwowania. ChatGPT przyznaje się do błędów i ciężko wyprowadzić go z równowagi.\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"g1QUVgIpiRbZ"}}]}