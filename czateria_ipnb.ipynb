{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Zadanie 1.**\n",
        "\n",
        "\n",
        "• wypełnianie deklaracji PIT - nie wymaga inteligencji człowieka, ponieważ zadanie to polega na wstawieniu danych wartości według ustalonych reguł\n",
        "\n",
        "• streszczanie tekstu - wymaga inteligencji człowieka, ponieważ zadanie to wymaga zrozumienia, analizy znaczeniowej i umiejętności wyciągnięcia myśli przewodniej tesktu w streszconej wersji\n",
        "\n",
        "• tłumaczenie tekstu - wymaga inteligencji człowieka, ponieważ potrzebna jest umiejętność dopasowania odpowiedniego tłumaczenia słowa do kontekstu i całościowego zrozumienia zdania\n",
        "\n",
        "• klasyfikacja tekstu do kategorii tematycznych -nie wymaga inteligencji człowieka, gdyż można dopasować poprzez słowa kluczowe\n",
        "\n",
        "• odpowiadanie na proste pytania zadawane w języku naturalnym (np. polskim) - zależy od definicji prostego pytania, jeśli rozumiane jest przez to typowe, częste pytanie w danej sytuacji to nie jest potrzebna, natomiast nawet proste składniowo pytania mogą mieć skomplikowaną, nieprzewidywalną odpowiedź\n",
        "\n",
        "• układanie rozkładu jazdy transportu miejskiego - zależy, bez użycia inteligencji jest to możliwe za pomocą np. algorytmów optymalizacyjnych, może być to jednak bardzo powolny i podatny na dynamiczne sytuacje (np. specjalne okoliczności, zapotrzebowanie pasażerów, obszar) proces, w przypadku dużej ilości zmiennych może być trudne lub niemożliwe posłużenie się mechanicznymi sposobami\n",
        "\n",
        "• programowanie (pisanie programów komputerowych) - wymaga, gdyż przed napisaniem programu potrzebny jest pomysł, stworzenie jego zamysłu, umiejętność twórczego rozwiązywania problemów.\n",
        "\n",
        "\n",
        "• „programowanie” kanałów telewizyjnych - nie wymaga inteligencji człowieka, przypisywanie do przycisków pilota odpowiednich programów odbywa się czysto schematowo\n",
        "\n",
        "• testowanie oprogramowania - wymaga inteligencji człowieka, potrzebne jest nieszablonowe myślenie, aby sprawdzić i dojść do niespotykanych sytuacji, danych, tworzenie scenariuszy testów\n",
        "\n",
        "• komponowanie muzyki - wymaga inteligencji człowieka, gdyż jest to bardzo twórczy, kreatywny proces, często poddawany emocjom, uczuciom estetycznym, wymagający tworzenia czegoś nowego, wychodzenia poza schematy i ogólnie przyjęte formuły\n",
        "\n",
        "• rozwiązywanie układów równań - przy prostych nie wymaga inteligencji człowieka, bo następuje tutaj jedynie proste postępowanie według schematu, ustalonych sposobów działania, podstawiania i zamieniania, natomiast przy bardzo skomplikowanych układach mogą nie istnieć sprawdzone algorytmiczne sposoby i potrzebna jest inwencja twórcza\n",
        "\n",
        "• symboliczne obliczanie pochodnych funkcji - nie wymaga, tak jak wyżej, potrzebne jest jedynie podstawienie odpowiednich wartości do wzoru według określonych reguł\n",
        "\n",
        "• symboliczne całkowanie funkcji - wymaga inteligencji człowieka, gdyż w pewnych przypadkach brak jest określonego wzoru i całkowanie przybiera wtedy formę twórczego procesu, aby do jakiegoś znanego wzoru doprowadzić\n",
        "\n",
        "• kierowanie samochodem - wymaga inteligencji człowieka, gdyż jest to bardzo skomplikowany proces, wymagający różnorakich decyzji w różnych sytuacjach, niepodlegający żadnym utartym schematom, przewidywać zachowania innych i nagłe zmiany w środowisku\n"
      ],
      "metadata": {
        "id": "3TiK8kgOGUYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zadanie 2.**\n",
        "\n",
        "Problemy, które można uznać za mieszczące się w zakresie sztucznej inteligencji to:\n",
        "\n",
        "• streszczanie tekstu - można\n",
        "\n",
        "• tłumaczenie tekstu - można\n",
        "\n",
        "• klasyfikacja tekstu do kategorii tematycznych - można, ale nie trzeba, sam system mechaniczny jest w stanie dopasować słowa kluczowe do kategorii\n",
        "\n",
        "• odpowiadanie na proste pytania zadawane w języku naturalnym - można ale nie trzeba (nie odpowiedzi “mądre”, ale sensowne poprzez wybór na podstawie słów kluczowych, klasy pytania)\n",
        "\n",
        "• rozwiązywanie układów równań - do skomplikowanych można\n",
        "\n",
        "• układanie rozkładu jazdy - do skomplikowanych można\n",
        "\n",
        "• rozwiązywanie układów równań liniowych - nie trzeba, są to schematyczne sposoby\n",
        "\n",
        "• symboliczne obliczanie pochodnych -nie trzeba\n",
        "\n",
        "• symboliczne całkowanie -można\n",
        "\n",
        "• kierowanie samochodem -można, jest w stanie\n",
        "\n",
        "Ponieważ sztuczna inteligencja umożliwia nam automatyczne i szybkie różne modyfikowania tekstów i innych zadań z tym związanych, bezproblemowo może stworzyć rozkład jazdy(także w formie obrazku). Co więcej w zakresie sztucznej inteligencji znajduje sie również kierowanie samochodem, które nie wymaga ingerencji człowieka.\n"
      ],
      "metadata": {
        "id": "Gm2UHeg9J1rR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zadanie 3.**\n",
        "\n",
        "1. Odpowiadanie na pytania klientów w telefonicznej infolinii i odpowiadanie na pytania klientów w internetowej infolinii są często nie do końca skuteczne przez sztuczne systemy, ponieważ zdarza się, że klient zadaje takie pytanie, na które sztuczne systemy nie są przygotowane. Mogą sobie nie radzić z niestandardowymi, szablonowymi pytaniami.\n",
        "\n",
        "2. Rozmowa towarzyska może byc skutecznie imitowana, bo systemy są w stanie generować żarty, opowiadać o różnych tematach na podstwie danych. Jedynie co można zarzucić to, że nie są w stanie tak jak ludzie zrozumieć w pełni emocji i relacji międzyludzkich - to sprawia, że są bardziej mechaniczne.\n",
        "\n",
        "3. Co do dyskusji politycznej, systemy są w stanie generować odpowiedzi oparte na faktach oraz analizach dostępnych danych politycznych. Może istnieć problem w rozmowie o aktualnych wydarzeniach chyba, że systemy te są regularnie aktualizowane.\n",
        "\n",
        "4. Dyskusja naukowa - systemy mogą generować odpowiedzi oparte na dostępnej wiedzy naukowej i logicznie uzasadniać swoje argumenty, brakuje im myśli twórvzej i pełnego zrozumienia koncepcji, co ogranicza zdolność do pełnej dyskusji naukowej."
      ],
      "metadata": {
        "id": "joIeTVrwMMWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zadanie 4.**\n",
        "\n",
        "\n",
        " Celem bota udającego człowieka (test turinga) jest przekonanie użytkownika, że rozmawia z człowiekiem. Bot dąży do tego, by imitować ludzką komunikację i ukrywać swoją tożsamość jako maszyny. W tym przypadku, test Turinga sprawdza, czy użytkownik potrafi odróżnić bota od prawdziwej osoby. Natomiast celem bota asystenta służącego jest ułatwienie wykonywania zadań lub dostarczanie odpowiednich informacji. Bot-asystent nie próbuje udawać człowieka, lecz skupia się na jak najbardziej efektywnej i przejrzystej pomocy użytkownikowi, np. odpowiada na pytania, pomaga w nawigacji, czy wykonuje inne zadania w imieniu użytkownika.\n",
        "\n",
        " Bot taki jak chatGPT ma gotowe żarty i nie potrafi rozbawić w ,,ludzkim stylu'', natomiast cleverbot nie miał z tym problemu, co dawało poczucie interacji z człowiekiem. Choć nie zawsze odpowiadał sensownie i nie radził sobie do końca z powracaniem do wcześniejszsych tematów. Nie podał mi żadnego cytatu, a chat GPT bez problemowo mi przedstwił losowy cytat (Elona Musk'a). Bota udającego człowieka jest łatwiej zdenerwować niż bota-asystenta, ponieważ pierwszy wykłóca sie, a drugi pyta czemu w dany sposób się myśli albo coś twierdzi. chatGPT zadawał pytania bardziej otwarte i skłaniające do odpowiedzi.  ChatGPT również zdecydowanie lepiej radził sobie z powracaniem do wcześniejszych tematów jak i z odpowiednią reakcją na moje odpowiedzi. Bot był do tego niechętny, ale wiadomości wymieniane z nim starały się imitować rozmowę z drugim człowiekiem,rozmowa z nim imitowała rozmowe z kolegą/koleżanką, a ChatGPT nie dawał takiego poczucia, mimo tego, że też można prowadzić z nim rozmowe o wielu tematach. Bot-asystent lepiej odpowiadał na pytania oraz bardziej angażował sie w rozowę poprzez stawianie pytań, w przeciwieństwie do cleverbot'a, który niechętnie to robił. Podsumowując chatGPT lepiej radził sobie z odpowiadaniem na pytania, wykonywaniem zadanych działań i utrzymywaniem rozmowy, ale nie wyrazał się w ,,luźny'' sposób tak jak robił to bot udający człowieka. On natomiast przy zapytaniu o pomoc zadawał pytanie wyrwane z kontekstu.\n"
      ],
      "metadata": {
        "id": "E_GiIivKSBnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "95hA2oOIMI4R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHR-8GY4Db3A"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ]
}